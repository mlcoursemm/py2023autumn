{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Python10-OpenCV_extra/logos.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегодня речь пойдёт про обработку изображений в python. Тема необъятная, но какие-то основы мы разберём. Помимо работы с картинками, мы посмотрим как на коленке обучить распознавание цифр и в несколько строк кода запустить детектор лиц с вебкамеры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pillow - это Python Imaging Library (PIL). Библиотека, добавляющая простую поддержку изображений: открыть, манипулировать, сохранить. \n",
    "Установка:\n",
    "pip install pillow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pil_image = Image.open(\"Python10-OpenCV_extra/what_is_pillow.jpeg\")\n",
    "\n",
    "my_pil_image.show() # чтобы посмотреть в отдельном окне\n",
    "display(my_pil_image) # чтобы посмотреть прямо тут "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тип объекта\n",
    "type(my_pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотреть информацию о изображении\n",
    "print(\"Format: {0}\\nSize: {1}\\nMode: {2}\".format(my_pil_image.format, my_pil_image.size, my_pil_image.mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтобы не путать очередность высоты и ширины, можно вызывать их напрямую\n",
    "print('width: {}, height: {}'.format(my_pil_image.width, my_pil_image.height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранить изображение\n",
    "my_pil_image.save('Python10-OpenCV_extra/what_is_pillow.png', 'png') \n",
    "# Так можно сохраниить в одном любом популярном формате, например jpg или png (более 30 форматов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Большая часть лично моего общения с PIL сводится именно к этим базовым действиям, которые легко, просто и быстро сделать. Что-то более сложное обычно делается другими методами. \n",
    "\n",
    "Дело в том что PIL рассматривает изображение именно как изображение, а не как массив пикселей с которыми было бы легко работать. \n",
    "\n",
    "Однако есть ещё кое-какие полезные функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кроп\n",
    "cropped = my_pil_image.crop((200, 200, 500, 350))\n",
    "display(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Различные фильтры, например блюр\n",
    "from PIL import ImageFilter \n",
    "\n",
    "blurred = cropped.filter(ImageFilter.BLUR)\n",
    "display(blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оттенки серого\n",
    "grayscale = cropped.convert('L') \n",
    "display(grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поворот\n",
    "rotated = cropped.rotate(180)\n",
    "display(rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изменение размера\n",
    "resized = cropped.resize((128,128))\n",
    "display(resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение по ссылке из интернета.\n",
    "import requests\n",
    "\n",
    "url = 'https://i.pinimg.com/originals/db/d0/79/dbd0790244b52e00d03c5d8be3b8d4d1.jpg'\n",
    "\n",
    "try:\n",
    "    resp = requests.get(url, stream=True).raw    \n",
    "except requests.exceptions.RequestException as e:  \n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    url_img = Image.open(resp).resize((300,300))\n",
    "except IOError:\n",
    "    print(\"Unable to open image\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "display(url_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рисование\n",
    "from PIL import ImageDraw\n",
    "\n",
    "idraw = ImageDraw.Draw(url_img)\n",
    "\n",
    "idraw.rectangle((10, 70, 200, 100), fill='red')\n",
    "idraw.text((30, 80), \"No way you are tired!\", 40)\n",
    "display(url_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рисовать можно много чего, множество свойств, детально посмотреть можно тут \n",
    "https://pillow.readthedocs.io/en/3.1.x/reference/ImageDraw.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Склейка картинок\n",
    "def img_concat(im1, im2):    \n",
    "    # Создадим новое изображение с удвоенной высотой\n",
    "    dst = Image.new('RGB', (im1.width, im1.height + im2.height)) \n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (0, im1.height))\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_img = img_concat(grayscale, blurred)\n",
    "display(merged_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом с PIL завершим.\n",
    "Запомним вот что: \n",
    "\n",
    "* Очередность каналов: RGB\n",
    "* Очередность размеров: ширина, высота\n",
    "* Очередность координат в прямоугольнике: X1, Y1, X2, Y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-image (skimage) - библиотека алгоритмов для обработки изображений, использующая numpy массивы для представления изображений.\n",
    "\n",
    "Установка: pip install scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличии от PIL теперь мы имеем в качестве объекта массив размера (height, width, channel), что дает нам простой доступ к каждому пикселю. В качестве примера удобства numpy нашёл вот такой код, рисующий шахматную доску в четыре строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "check = np.zeros((8, 8))\n",
    "check[::2, 1::2] = 1 # чётные\n",
    "check[1::2, ::2] = 1 # нечётные\n",
    "plt.imshow(check, cmap='gray') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C matplotlib мы разобрались ранее, поэтому постараемся пользоваться им минималистично чтобы не отвлекаться от сегодняшней темы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io # Модуль чтобы читать-писать в разных форматах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Открыть изображение\n",
    "my_image = io.imread('Python10-OpenCV_extra/I_know_python.jpeg')\n",
    "plt.imshow(my_image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(my_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отлично, посмотрим свойства как у numpy\n",
    "print('dtype: {}; shape: {}'.format(my_image.dtype, my_image.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Заглянем внутрь\n",
    "my_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на нормировку - значения от 0 до 255. Skimage работает и с float, поэтому надо держать это в голове."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage import img_as_float # Можно было просто разделить на 255, но так надёжнее\n",
    "\n",
    "my_image_float = img_as_float(my_image) \n",
    "my_image_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(my_image_float) \n",
    "# Понимание изображения не утрачено"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение изображения/\n",
    "io.imsave('Python10-OpenCV_extra/skimage_png_emaple.png', my_image)\n",
    "# Указывать выходной формат не обязательно, он сам поймёт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переведём изображение из PIL\n",
    "skimage_image = np.array(my_pil_image)\n",
    "plt.imshow(skimage_image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переведём в PIL\n",
    "pil_image = Image.fromarray(my_image)\n",
    "display(pil_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Методы \"открыть\", \"посмотреть\" и \"сохранить\" неизменно лидируют по популярности. Но это можно было и в PIL. Теперь давайте разбираться зачем нам skimage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import filters # Множество простых фильтров под любые потребности\n",
    "\n",
    "# Заблюрим изображение при помощи гауссова фильтра\n",
    "my_image_gaussian = filters.gaussian(my_image, sigma=3)\n",
    "plt.imshow(my_image_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color # Любые трансформации цветов \n",
    "\n",
    "img_gray = color.rgb2gray(my_image)\n",
    "#plt.imshow(img_gray)\n",
    "plt.imshow(img_gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Найдём на изображении контуры несколькими способами.\n",
    "fig=plt.figure(figsize=(10, 10))\n",
    "fig.add_subplot(2, 2, 1)\n",
    "plt.imshow(filters.roberts(img_gray), cmap='gray') # Фильтр Робертса\n",
    "fig.add_subplot(2, 2, 2)\n",
    "plt.imshow(filters.prewitt(img_gray), cmap='gray') # Фильтр Прюитта\n",
    "fig.add_subplot(2, 2, 3)\n",
    "plt.imshow(filters.scharr(img_gray), cmap='gray') # Фильтр Щара (?)\n",
    "fig.add_subplot(2, 2, 4)\n",
    "plt.imshow(filters.sobel(img_gray), cmap='gray') # Фильтр Собеля\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Прогоним изображение через фильтры по порогу, рассчитанному разными методами, реализованными в skimage\n",
    "fig = filters.try_all_threshold(img_gray, figsize=(10, 10), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure # нелокальные фильтры (используют большую часть картинки или всю её)\n",
    "\n",
    "fig=plt.figure(figsize=(10, 10))\n",
    "fig.add_subplot(2, 3, 1)\n",
    "plt.imshow(my_image)\n",
    "\n",
    "# Гамма коррекция\n",
    "fig.add_subplot(2, 3, 2)\n",
    "plt.imshow(exposure.adjust_gamma(my_image, 2))\n",
    "\n",
    "# Логарифмическая коррекция\n",
    "fig.add_subplot(2, 3, 3)\n",
    "plt.imshow(exposure.adjust_log(my_image, 0.7))\n",
    "\n",
    "# Выравнивание гистрограмм\n",
    "fig.add_subplot(2, 3, 4)\n",
    "plt.imshow(exposure.equalize_hist(my_image))\n",
    "\n",
    "# Адаптивное выравнивание гистограмм\n",
    "fig.add_subplot(2, 3, 5)\n",
    "plt.imshow(exposure.equalize_adapthist(my_image))\n",
    "\n",
    "# Сигмоидальная настройка\n",
    "fig.add_subplot(2, 3, 6)\n",
    "plt.imshow(exposure.adjust_sigmoid(my_image))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Более сложные алгоритмы, нацеленные на широкий спектр задач. \n",
    "# Зачастую на выходе имеем не изображение, а набор признаков\n",
    "from skimage import feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(20, 30))\n",
    "fig.add_subplot(1, 3, 1)\n",
    "plt.imshow(img_gray, cmap='gray') \n",
    "fig.add_subplot(1, 3, 2)\n",
    "\n",
    "# Детектор Кенни\n",
    "plt.imshow(feature.canny(img_gray), cmap='gray') \n",
    "fig.add_subplot(1, 3, 3)\n",
    "\n",
    "# Гистограммы ориентированных градиентов (HOG)\n",
    "fd, hog_image = feature.hog(my_image, orientations=16, pixels_per_cell=(4, 4),\n",
    "                    cells_per_block=(1, 1), visualize=True, multichannel=True)\n",
    "plt.imshow(hog_image) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте возьмём из модуля features каскадный классификатор, найдём его предобученные веса для объекта \"фронтальное лицо\", поищем лицо на нашей фотографии и построим прямоугольник"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "from skimage import data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В модуле data находятся разные сохранённые данные: предобученные алгоритмы, изображения, базы данных и прочее. Не будем на этом фокусироваться, потому что само по себе оно никогда не нужно, а когда вдруг понадобится - всегда есть ссылка. Зачастую этим модулем удобно пользоваться для воспроизведения примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = io.imread('Python10-OpenCV_extra/I_know_python.jpeg')\n",
    "\n",
    "trained_file = data.lbp_frontal_face_cascade_filename()\n",
    "\n",
    "# Initialize the detector cascade.\n",
    "detector = feature.Cascade(trained_file)\n",
    "detected = detector.detect_multi_scale(img=my_image,\n",
    "                                       scale_factor=1.05,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(10, 10),\n",
    "                                       max_size=(300, 300))\n",
    "print(detected)\n",
    "\n",
    "plt.imshow(my_image)\n",
    "img_desc = plt.gca() # get current axis\n",
    "\n",
    "for patch in detected:\n",
    "    img_desc.add_patch(\n",
    "        Rectangle(\n",
    "            (patch['c'], patch['r']),\n",
    "            patch['width'],\n",
    "            patch['height'],\n",
    "            fill=False,\n",
    "            color='r',\n",
    "            linewidth=2\n",
    "        )\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратили внимание что прямоугольник задаётся не как в PIL?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте рассмотрим ещё одну нетривиальную задачу, сначала испортим изображение случайным шумом, а потом попробуем его восстановить. Ривз, устал, давайте сменим изображение на более простое текстуру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модуль восстановления/улучшения изображений. Возьмём самые популярные:\n",
    "from skimage.restoration import denoise_tv_chambolle, denoise_bilateral, denoise_wavelet\n",
    "\n",
    "# Случайный шум (соль и перец), с ним и будем бороться\n",
    "from skimage.util import random_noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = np.array(cropped)\n",
    "\n",
    "sigma = 0.155\n",
    "noisy = random_noise(original, var=sigma**2)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=4, figsize=(8, 5),\n",
    "                       sharex=True, sharey=True)\n",
    "\n",
    "plt.gray()\n",
    "\n",
    "ax[0, 0].imshow(noisy)\n",
    "ax[0, 0].axis('off')\n",
    "ax[0, 0].set_title('Noisy')\n",
    "ax[0, 1].imshow(denoise_tv_chambolle(noisy, weight=0.1, multichannel=True))\n",
    "ax[0, 1].axis('off')\n",
    "ax[0, 1].set_title('TV')\n",
    "ax[0, 2].imshow(denoise_bilateral(noisy, sigma_color=0.05, sigma_spatial=15,\n",
    "                multichannel=True))\n",
    "ax[0, 2].axis('off')\n",
    "ax[0, 2].set_title('Bilateral')\n",
    "ax[0, 3].imshow(denoise_wavelet(noisy, multichannel=True, rescale_sigma=True))\n",
    "ax[0, 3].axis('off')\n",
    "ax[0, 3].set_title('Wavelet denoising')\n",
    "\n",
    "ax[1, 1].imshow(denoise_tv_chambolle(noisy, weight=0.2, multichannel=True))\n",
    "ax[1, 1].axis('off')\n",
    "ax[1, 1].set_title('(more) TV')\n",
    "ax[1, 2].imshow(denoise_bilateral(noisy, sigma_color=0.1, sigma_spatial=15,\n",
    "                multichannel=True))\n",
    "ax[1, 2].axis('off')\n",
    "ax[1, 2].set_title('(more) Bilateral')\n",
    "ax[1, 3].imshow(denoise_wavelet(noisy, multichannel=True, convert2ycbcr=True,\n",
    "                                rescale_sigma=True))\n",
    "ax[1, 3].axis('off')\n",
    "ax[1, 3].set_title('Wavelet denoising\\nin YCbCr colorspace')\n",
    "ax[1, 0].imshow(original)\n",
    "ax[1, 0].axis('off')\n",
    "ax[1, 0].set_title('Original')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кто-то, конечно, может сказать что восстанавливая изображение мы испортили его, но тут уж на вкус и цвет все метрики разные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наш лимит времени на skimage исчерпан, и мы много чего не посмотрели и никак не можем этого успеть в рамках половины лекции. \n",
    "![no time](Python10-OpenCV_extra/no_time.jpg)\n",
    "Что нам надо запомнить о skimage? В нём есть много алгоритмов различной обработки изображений, начиная от примитивных, заканчивая достаточно интеллектуальными:     \n",
    "* Geometric transformations, \n",
    "* Color space manipulation,\n",
    "* Analysis,\n",
    "* Filtering, \n",
    "* Segmentation,\n",
    "* Morphology,\n",
    "* Feature detection, \n",
    "* more \n",
    "\n",
    "Достаточно много примеров можно найти на официальном сайте https://scikit-image.org/docs/dev/auto_examples/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV - Open Source Computer Vision Library. \n",
    "Библиотека алгоритмов компьютерного зрения, обработки изображений и численных алгоритмов общего назначения с открытым кодом. Реализована на C/C++, также разрабатывается для других языков, в том числе python. Может свободно использоваться в любых целях, за исключением нескольких платных пакетов. Активно использует параллелизм, как CPU так и на GPU, и вообще достаточно активно внедряет всё новое в свою библиотеку.\n",
    "\n",
    "На официальном сайте написано что у них около 50 тысяч пользователей в сообществе, и более 18 млн скачек библиотеки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установка не такая простая как это было всегда до этого, и если мы хотим чтобы библиотека имела полный функционал (например, можно было работать с вебкамерой, и видео в целом), то придётся заморочиться. Но чтобы просто попробовать - достаточно будет **pip install opencv-python**. Более правильные варианты установки лучше гуглить, потому что библиотека постоянно обновляется, и варианты установки могут розниться в зависимости от того, что именно вы хотите с ней делать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем так\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим любимые команды\n",
    "test_image = cv2.imread(\"Python10-OpenCV_extra/opencv.jpg\")\n",
    "(h, w, d) = test_image.shape \n",
    "# Сначала высота, потом ширина, дальше каналы\n",
    "print(\"height={}, width={}, depth={}\".format(h, w, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Image\", test_image)\n",
    "cv2.waitKey(0)                  # ждёт любую кнопку, с задержкой 0 милисекунд\n",
    "cv2.destroyAllWindows()         # закрывает все открытые ранее окна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В самом Jupyter работать будет только через matplotlib.\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самые наблюдательные из вас, могут заметить, что цвет лица на меме слегка отдаёт голубизной. Дело тут не в не в том что мем дефектный, а в том что OpenCV более 20 лет, он был создан раньше чем был принят формат RGB. Ранее был формат BGR, и он сохранён в библиотеке. И если в самом OpenCV это не вызывает внутренних противоречий, то при совместной работе с другими пакетами, например matplotlib надо об этом не забывать, чтобы не расплескать синеву по данным. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_RGB = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(test_img_RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К слову, то же самое можно было сделать и руками, вспомнив первые лекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_another_RGB = test_image[:,:,::-1]\n",
    "plt.imshow(test_img_another_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(type(test_image)) # Тут ничего нового\n",
    "print(test_image) # Тут тоже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv2.imwrite('Python10-OpenCV_extra/new_img_opencv.jpg', test_img_RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забываем что чтобы сделать RGB мы поменяли каналы, но это не значит что opencv передумал, он по прежнему думает что это BGR, и при записи учтёт это."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В OpenCV есть множество алгоритмов, схожих с skimage, фильтры, обработка, восстановление и т.д. Но основная направленность всё же на компьютерное зрение. Его давайте и рассмотрим на примерах. Решим великую задачу машинного обучения - распознавание цифр, при помощи OpenCV, разумеется. \n",
    "\n",
    "Продвинутые алгоритмы для работы с большими сложными базами вам рассказывают на курсе машинного обучения, а здесь мы попробуем насладиться простотой и обучиться распознавать простые цифры по одной картинке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "train_image = cv2.imread('./Python10-OpenCV_extra/data/train.png') \n",
    "# Проведём предобработку как ранее пробовали на skimage\n",
    "gray = cv2.cvtColor(train_image, cv2.COLOR_BGR2GRAY)      # переводим в серый\n",
    "blur = cv2.GaussianBlur(gray, (5, 5), 0)                  # блюрим (чтобы \"сгладить\" изображение)\n",
    "thresh = cv2.adaptiveThreshold(blur, 255, 1, 1, 11, 2)    # фильтруем по порогу\n",
    "\n",
    "fig=plt.figure(figsize=(20, 20))\n",
    "fig.add_subplot(4, 1, 1)\n",
    "plt.imshow(train_image)\n",
    "fig.add_subplot(4, 1, 2)\n",
    "plt.imshow(gray, cmap='gray')\n",
    "fig.add_subplot(4, 1, 3)\n",
    "plt.imshow(blur, cmap='gray')\n",
    "fig.add_subplot(4, 1, 4)\n",
    "plt.imshow(thresh, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Найдём контуры\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#print(contours)\n",
    "#print(len(contours))      # должно быть 125  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ну, раз ничего непонятно, то давайте просто посмотрим\n",
    "train_image_copy = train_image.copy()\n",
    "for cnt in contours:        \n",
    "    [x, y, w, h] = cv2.boundingRect(cnt) # извлекаем левый верхний угол и размеры контуров\n",
    "    # А вот чтобы построить прямоугольник - надо задавать два набора координат!\n",
    "    cv2.rectangle(train_image_copy, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "plt.imshow(train_image_copy, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь понятно, некоторые цифры получили несколько \"сработок\". Не беда, возьмём только самые большие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заведём пустые места для записи лэйблов \n",
    "samples = np.empty((0, 100), np.float32)\n",
    "responses = []\n",
    "keys = [i for i in range(48, 58)] # соответствуюет клавишам цифр от 0 до 9 на стандартной раскладке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напишем простенький алгоритм интерактивной разметки\n",
    "for cnt in contours:    \n",
    "    if cv2.contourArea(cnt) > 50: # отсеиваем все малые контуры\n",
    "        [x, y, w, h] = cv2.boundingRect(cnt)\n",
    "\n",
    "        if h > 28: # отсеиваем \"половинки\" цифр\n",
    "            train_image_copy = train_image.copy()\n",
    "            cv2.rectangle(train_image_copy, (x, y), (x + w, y + h), (0, 0, 255), 2)            \n",
    "            \n",
    "            # Выводим новый контур\n",
    "            cv2.imshow('norm', train_image_copy)\n",
    "            \n",
    "            # И ждём разметку для него с клавиатуры\n",
    "            key = cv2.waitKey(0)\n",
    "            \n",
    "            # Сделаем кнопку \"q\" стоп-словом, на случай если надоест размечать\n",
    "            if key == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "            \n",
    "            elif key in keys:\n",
    "                # Понимаем и запоминаем разметку с клавиатуры\n",
    "                responses.append(int(chr(key))) \n",
    "                \n",
    "                # Находим соответствующий ему фрагмент изображения\n",
    "                roi = thresh[y:y + h, x:x + w]\n",
    "                \n",
    "                # Для удобства - отнормируем на 10 пикселей\n",
    "                roismall = cv2.resize(roi, (10, 10)) \n",
    "                sample = roismall.reshape((1, 100)) \n",
    "                \n",
    "                # И тоже запомним\n",
    "                samples = np.append(samples, sample, 0)                \n",
    "                \n",
    "\n",
    "responses = np.array(responses, np.float32)\n",
    "responses = responses.reshape((responses.size, 1))\n",
    "print (\"training complete\")\n",
    "\n",
    "samples = np.float32(samples)\n",
    "responses = np.float32(responses)\n",
    "\n",
    "cv2.imwrite(\"./Python10-OpenCV_extra/data/train_result.png\", train_image)\n",
    "np.savetxt('./Python10-OpenCV_extra/data/generalsamples.data', samples)\n",
    "np.savetxt('./Python10-OpenCV_extra/data/generalresponses.data', responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим KNN на наших данных\n",
    "model = cv2.ml.KNearest_create()\n",
    "model.train(samples, cv2.ml.ROW_SAMPLE, responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = cv2.imread('./Python10-OpenCV_extra/data/test.png') \n",
    "# Проведём предобработку как ранее пробовали на skimage\n",
    "gray = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)      # переводим в серый\n",
    "blur = cv2.GaussianBlur(gray, (5, 5), 0)                  # блюрим (чтобы \"сгладить\" изображение)\n",
    "thresh = cv2.adaptiveThreshold(blur, 255, 1, 1, 11, 2)    # фильтруем по порогу\n",
    "\n",
    "fig=plt.figure(figsize=(20, 20))\n",
    "fig.add_subplot(4, 1, 1)\n",
    "plt.imshow(test_image)\n",
    "fig.add_subplot(4, 1, 2)\n",
    "plt.imshow(gray, cmap='gray')\n",
    "fig.add_subplot(4, 1, 3)\n",
    "plt.imshow(blur, cmap='gray')\n",
    "fig.add_subplot(4, 1, 4)\n",
    "plt.imshow(thresh, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим чистую картинку такого же размера, чтобы написать на ней результаты распознавания\n",
    "out = np.zeros(test_image.shape, np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Повторим поиск и отсев контуров\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt in contours:\n",
    "    if cv2.contourArea(cnt) > 50:\n",
    "        [x, y, w, h] = cv2.boundingRect(cnt)\n",
    "        if h > 28:\n",
    "            cv2.rectangle(test_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            roi = thresh[y:y + h, x:x + w]\n",
    "            roismall = cv2.resize(roi, (10, 10))\n",
    "            roismall = roismall.reshape((1, 100))\n",
    "            roismall = np.float32(roismall)\n",
    "            \n",
    "            # Ищем самый похожий фрагмент по размеченному трейну\n",
    "            retval, results, neigh_resp, dists = model.findNearest(roismall, k=1)\n",
    "            \n",
    "            # напишем его на нашей чистой картинке на соответсвующей позиции\n",
    "            string = str(int((results[0][0])))\n",
    "            cv2.putText(out, string, (x, y + h), 0, 1, (0, 255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ну всё, давайте смотреть что вышло\n",
    "cv2.imshow('out', out)\n",
    "\n",
    "key = cv2.waitKey(0)\n",
    "if key == ord('q'):\n",
    "    cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, всё отлично распозналось, если я не ошибся при разметке и не заленился сделать хотя бы пару строк. Это произошло в основном потому что тест простой и очень похож на трейн. Но что делать если тест чуть сложнее? Ну, например, появился небольшой шум, а наш простенький алгоритм не очень устойчив. Нам ведь не хочется чтобы из-за нескольких новых пикселей на изображении наша система порушилась и точность упала в ноль? Давайте рассмотрим пару методов морфологических преобразований, они не решат всех проблем, но укажут направление, в котором можно сходить за решением получше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('Python10-OpenCV_extra/j.png')\n",
    "\n",
    "# Эрозия - \"подтачиваем\" границы\n",
    "kernel = np.ones((5,5),np.uint8) \n",
    "# Ядро. Проходим ним картинку как скользящим окном. Если условие выполняется, то это 1, если нет - 0\n",
    "erosion = cv2.erode(img,kernel,iterations = 1)\n",
    "\n",
    "# Расширение. Проводим операцию с тем же ядром. Если условие условие не выполняется - то 1\n",
    "dilation = cv2.dilate(img,kernel,iterations = 1)\n",
    "\n",
    "fig=plt.figure(figsize=(10, 10))\n",
    "\n",
    "fig.add_subplot(1, 3, 1)\n",
    "plt.imshow(img, cmap='gray') \n",
    "\n",
    "fig.add_subplot(1, 3, 2)\n",
    "plt.imshow(erosion, cmap='gray') \n",
    "\n",
    "fig.add_subplot(1, 3, 3)\n",
    "plt.imshow(dilation, cmap='gray') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_opening = cv2.imread('Python10-OpenCV_extra/opening.png')\n",
    "img_closing = cv2.imread('Python10-OpenCV_extra/closing.png')\n",
    "\n",
    "# Открытие: эрозия + расширение\n",
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# Закрытие: расширение + эрозия\n",
    "closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "fig=plt.figure(figsize=(10, 10))\n",
    "\n",
    "fig.add_subplot(2, 2, 1)\n",
    "plt.imshow(img_opening, cmap='gray') \n",
    "\n",
    "fig.add_subplot(2, 2, 2)\n",
    "plt.imshow(opening, cmap='gray') \n",
    "\n",
    "fig.add_subplot(2, 2, 3)\n",
    "plt.imshow(img_closing, cmap='gray') \n",
    "\n",
    "fig.add_subplot(2, 2, 4)\n",
    "plt.imshow(closing, cmap='gray') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка видео\n",
    "Следующий пример будет по работе с видеопотоком. \n",
    "Давайте поработаем с видео, например поищем там лица."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "my_video = \"./Python10-OpenCV_extra/my_video.mp4\"\n",
    "video = cv2.VideoCapture(my_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video)\n",
    "print(type(video))\n",
    "\n",
    "# Проверим размеры и скорость\n",
    "print('Frame width: {}'.format(video.get(cv2.CAP_PROP_FRAME_WIDTH)))\n",
    "print('Frame height: {}'.format(video.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "print('FPS: {}'.format(video.get(cv2.CAP_PROP_FPS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот так обращаемся к видеопотоку, но не считываем, а только открываем. Считывать будем покадрово."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:            \n",
    "    ret, frame = video.read()  \n",
    "    # ret отвечает за то есть ли из видеопотока какой-то return. Если нет то надо выходить из цикла.\n",
    "    # frame - кадр\n",
    "    \n",
    "    if not ret or cv2.waitKey(40) == ord('q'):\n",
    "        break  \n",
    "        \n",
    "    # ну а с кадром можно делать всё что и раньше мы делали с изображениями\n",
    "    cv2.imshow('Video', frame)\n",
    "   \n",
    "# обязательно завершить работу с видео\n",
    "video.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы цикл не ждал от нас сиюсекундного нажатия клавиши для сравнения с заданным ключом выхода, как это было нам удобно раньше, сделаем ожидание нажатие кнопки с задержкой: cv2.waitKey(1).\n",
    "Заметим, что в отпущенное видео нельзя зайти повторно, если не инициализировать его снова.\n",
    "Чтобы видео шло с реалистичной скоростью, надо отрегулирповать задержку между кадрами. Обычно это 25 кадров в секунду, что соответствует 40 милисекундам на кадр, но если вы имеете дело со скоростной камерой, или старым видео, то надо об этом не забыть. В нашем случае, видео хоть и старое, но скачано с ютьюба и там непонятный препроцесссинг, будем считать что это 25 кадров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не будем лезть в машинное обучение, и возьмём такой же каскад как смотрели в skimage. А предобученную модель качнём с официального гитхаба opencv https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./Python10-OpenCV_extra/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(face_cascade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:            \n",
    "    ret, frame = video.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1)\n",
    "    \n",
    "    # Draw rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    \n",
    "    if not ret or cv2.waitKey(40) == ord('q'):\n",
    "        break          \n",
    "    \n",
    "    cv2.imshow('Video', frame)   \n",
    "\n",
    "video.release() \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу видим ряд проблем. Во-первых лица не всегда находятся, во-вторых много ложных срабатываний, в-третьих видео стало тормозить. Мы конечно можем поиграться параметрами: ограничить минимальный размер лица, сделать шаги каскада поменьше, убрать задержку между кадрами... но действительно хорошего качества таким простым алгоритмом добиться не удастся. Давайте пока отложим борьбу за качество, а вместо этого попробуем вместо видеопотока из файла подсунуть видеопоток с вебкамеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "my_camera = cv2.VideoCapture(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 здесь это порядковый номер порта в который подключена камера. У ноутбука тоже 0, а вот если в ноутбук воткнуть вебкамеру, или просто к компьютеру подключить несколько, то они как-то будут пронумерованы, возможно в порядке подключения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_camera) \n",
    "print('Frame width: {}'.format(my_camera.get(cv2.CAP_PROP_FRAME_WIDTH)))\n",
    "print('Frame height: {}'.format(my_camera.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "print('FPS: {}'.format(my_camera.get(cv2.CAP_PROP_FPS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не слишком-то отличается от видео."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:            \n",
    "    ret, frame = my_camera.read() \n",
    "    \n",
    "    if not ret or cv2.waitKey(40) == ord('q'):\n",
    "        break  \n",
    "       \n",
    "    cv2.imshow('Webcam', frame)   \n",
    "    \n",
    "my_camera.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну и раз есть фреймы, то на них мы можем что-то попробовать запустить. Например, наш детектор лиц."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./Python10-OpenCV_extra/haarcascade_frontalface_default.xml')\n",
    "while True:            \n",
    "    ret, frame = my_camera.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1)\n",
    "    \n",
    "    # Draw rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    \n",
    "    if not ret or cv2.waitKey(10) == ord('q'):\n",
    "        break          \n",
    "    \n",
    "    cv2.imshow('Video', frame)   \n",
    "\n",
    "my_camera.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда базовые вещи мы посмотрели, можно посмотреть кое-что чуть сложнее. Чтобы у вас не осталось ощущения что мы сегодня изучали и занимались какими-то не очень важными вещами, которые и рамку-то вокруг лица нарисовать не могут, я все же подготовил детектор лиц получше на основе opencv. Есть модуль .dnn содержащий нейросетевые решения (много разных). Но мы не будем пользоваться каким-то совсем готовым и внесенным в пакет, потому что я что-то сходу не нашёл подходящего модуля под такую самую задачу, а вместо этого (погуглим, найдём и) зайдём на официальный гитхаб этого модуля https://github.com/opencv/opencv/tree/master/samples/dnn/face_detector и найдём там необученный модуль на caffe. Дальше (опять погуглив) легко найдём множество гитхабов, которые эту сеть обучили и выложили веса, например https://github.com/gopinath-balu/computer_vision/tree/master/CAFFE_DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# Архитектура с гита opencv\n",
    "configFile = \"Python10-OpenCV_extra/deploy.prototxt.txt\"\n",
    "\n",
    "# Обученные веса\n",
    "modelFile = \"Python10-OpenCV_extra/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "\n",
    "# Считываем модулем cv2.dnn\n",
    "net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "\n",
    "my_camera = cv2.VideoCapture(0) \n",
    "while True:            \n",
    "    ret, frame = my_camera.read() \n",
    "    \n",
    "    if not ret or cv2.waitKey(50) == ord('q'):\n",
    "        break      \n",
    "    \n",
    "    h, w = frame.shape[:2]\n",
    "    \n",
    "    # Полезная функция-помощник. Она вычитает из изображения среднее, масштабирует, и еще может менять каналы\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, \n",
    "    (300, 300), (104.0, 117.0, 123.0))\n",
    "    \n",
    "    # Подаём картинку в сеть\n",
    "    net.setInput(blob)\n",
    "    \n",
    "    # Получаем инференс\n",
    "    faces = net.forward()\n",
    "    \n",
    "    # Рисуем\n",
    "    for i in range(faces.shape[2]):\n",
    "            confidence = faces[0, 0, i, 2]\n",
    "            # Фильтруем по уверенности по порогу\n",
    "            if confidence > 0.5:\n",
    "                box = faces[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (x, y, x1, y1) = box.astype(\"int\")\n",
    "                cv2.rectangle(frame, (x, y), (x1, y1), (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.imshow('Webcam', frame)   \n",
    "    \n",
    "my_camera.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ура, наконец всё классно заработало!\n",
    "На этом этой оптимистической ноте лекция окончена. \n",
    "\n",
    "Небольшое заключение: **Skimage vs OpenCV**\n",
    "\n",
    "* **Skimage** хорош тем что изначально питонский, поэтому не возникнет никаких проблем совместимости. В нём больше алгоритмов обработки изображений и многие говорят что для обработки он *мощнее*.\n",
    "* **OpenCV** хорош встроенными алгоритмами компьютерного зрения, всяческим мульти-процессингом и большим сообществом разработчиков-пользователей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# На этом наш курс лекций окончен, ура!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По поводу оценок:\n",
    "\n",
    "    для зачёта нужно 40%\n",
    "    \n",
    "    для экзамена: \n",
    "        3 - 40%\n",
    "        4 - 60%\n",
    "        5 - 80%\n",
    "        \n",
    "Через неделю (в крайнем слуаче - через 2) мы устроим разбор домашних заданий. Решений мы показывать не будем, но на вопросы постараемся ответить. Все претензии, аппеляции, все организационные вопросы и прочее нужно спросить до этого дня или прям там. \n",
    "\n",
    "Пожалуйста проверьте свой */status* и убедитесь что там всё в порядке.\n",
    "\n",
    "Позднее \"**я не знал / я лежал в больнице / я был в другой стране / меня отчисляют если не сдам / я всё сделал но не посылал потому что не думал что мне это нужно**\" и прочие причины уже никак не могут ни на что повлиять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
